---
title: "task3"
author: "Nazar Demchuk"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# install.packages("BSDA")
library(BSDA)
```

```{r}
# make this example reproducible
n <- 12

# generating data
a <- function(k) {
  res <- (k * log(k * k * n + pi))
  return(res - floor(res))
}

X <- seq(1, 100)
for (idx in 1:100) {
  X[idx] = a(idx)
}

Y <- seq(1, 50)
for (idx in 1:50) {
  Y[idx] = a(idx)
}

# X
# Y
```

# Problem 1

### Maslenchenko Oleksandra

$$
H_0: \mu_1 = \mu_2 \space vs. \space H_1: \mu_1 \neq \mu_2; \space \sigma_1^2 = \sigma_2^2=1
$$

### Theory:

Since here we test means of two samples, variances are known and both sample sizes are large enough (larger than 30), we can use z-test. Also, since the alternative hypothesis states, that the mean of the first sample is not equal to the mean of the second sample, we will use two-sided z-test. First, let us derive it theoretically:

To estimate $\mu_1-\mu_2$ we can use $\bar{X}-\bar{Y}$ and it would be natural to reject $H_0$ if the obtained value is far from zero.

$$
C_{\alpha} = \brace(x, y): |\bar{X}-\bar{Y}|>c_{\alpha}
$$

Or in our case:

$$
C_{0.05} = \brace(x, y): |\bar{X}-\bar{Y}|>c_{0.05}
$$

According to the Central Limit Theorem, regardless of the distribution of the population, as long as the sample size is large enough (larger than 30), the sampling distribution of the mean will always be normally distributed.

So when we assume that $H_0$ is true, the distribution of $\bar{X} \sim N(\mu_x, \sigma^2/n)$ and $\bar{Y} \sim N(\mu_x, \sigma^2/m)$.

Hence, $\bar{X} - \bar{Y} \sim N(0, \sigma^2/n + \sigma^2/m)$.

$$
Z=Z(X, Y) := \sqrt{\frac{m \cdot n}{m + n}}\frac{\bar{X} - \bar{Y}}{\sigma}
$$

Since Z has standard normal distribution $Z \sim N(0, 1)$, for the test of size $\alpha$ (0.05 in our case):

$$
|z(x, y)| \geq z_{1-\alpha/2}
$$

And the corresponding p-value:

$$
p(x, y) = 2\cdot\Phi(-|z(x,y)|)
$$

### Calculating manually:

```{r}
#calculating z-statistics
z_stat <- sqrt(5000/150)*(mean(X)-mean(Y))
z_stat
#calculating p-value
p_value <- 2*pnorm(-abs(z_stat))
p_value

```

### Calculating using built-in function:

```{r}
#usng built-in function to test hypotheses using two-sided z-test
z_test <- z.test(x = X, y = Y, alternative = "two.sided", mu = 0, sigma.x = 1, sigma.y = 1, conf.level = 0.95)
z_test

#plot critical region

```

### Conclusion:

We know, that if p-value is small enough (less than or equal to the significance level $\alpha$, we reject $H_0$ and do not reject otherwise. The obtained p-value is 0.8546726 and the significance level is 0.05, hence, with 95% of confidence we do not reject $H_0$.

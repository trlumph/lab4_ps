---
title: "task3"
author: "Nazar Demchuk"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# install.packages("BSDA")
library(BSDA)
library(ggplot2)
```

```{r}
# make this example reproducible
n <- 12

# generating data
a <- function(k) {
  res <- (k * log(k * k * n + pi))
  return(res - floor(res))
}

X <- seq(1, 100)
for (idx in 1:100) {
  X[idx] = a(idx)
}

Y <- seq(1, 50)
for (idx in 1:50) {
  Y[idx] = a(idx)
}

# X
# Y
```

# Problem 1

### Maslenchenko Oleksandra

$$
H_0: \mu_1 = \mu_2 \space vs. \space H_1: \mu_1 \neq \mu_2; \space \sigma_1^2 = \sigma_2^2=1
$$

### Theory:

Since here we test means of two samples, variances are known and both sample sizes are large enough (larger than 30), we can use z-test. Also, since the alternative hypothesis states, that the mean of the first sample is not equal to the mean of the second sample, we will use two-sided z-test. First, let us derive it theoretically:

To estimate $\mu_1-\mu_2$ we can use $\bar{X}-\bar{Y}$ and it would be natural to reject $H_0$ if the obtained value is far from zero.

$$
C_{\alpha} = \brace(x, y): |\bar{X}-\bar{Y}|>c_{\alpha}
$$

According to the Central Limit Theorem, regardless of the distribution of the population, as long as the sample size is large enough (larger than 30), the sampling distribution of the mean will always be normally distributed.

So when we assume that $H_0$ is true, the distribution of $\bar{X} \sim N(\mu_x, \sigma^2/n)$ and $\bar{Y} \sim N(\mu_x, \sigma^2/m)$.

Hence, $\bar{X} - \bar{Y} \sim N(0, \sigma^2/n + \sigma^2/m)$.

$$
Z=Z(X, Y) := \sqrt{\frac{m \cdot n}{m + n}}\frac{\bar{X} - \bar{Y}}{\sigma}
$$

Since Z has standard normal distribution $Z \sim N(0, 1)$, for the test of size $\alpha$ (0.05 in our case):

$$
|z(x, y)| \geq z_{1-\alpha/2}
$$

And the corresponding p-value:

$$
p(x, y) = 2\cdot\Phi(-|z(x,y)|)
$$

### Calculating manually:

```{r}
#calculating z-statistics
z_stat <- sqrt(5000/150)*(mean(X)-mean(Y))
cat("z-score for two-sided z-test ", z_stat)

cat("\n")

#calculating p-value
p_value <- 2*pnorm(-abs(z_stat))
cat("p-value for two-sided z-test ", p_value)
```

### Calculating using built-in function:

```{r}
#usng built-in function to test hypotheses using two-sided z-test
z_test <- z.test(x = X, y = Y, alternative = "two.sided", mu = 0, sigma.x = 1, sigma.y = 1, conf.level = 0.95)
z_test
```

As we can see, the values obtained by calculating manually and using built-in functions match.

### Plot:

Now we can show all the obtained data on the plot: 2.5% and 97.5% percentiles, p-value and z-score. Rejection regions are filled with red color. Since z-score does not belong to them, we do not have to reject $H_0$.

```{r}
dnorm_limit <- function(x) {
    y <- dnorm(x)
    y[x >= qnorm(0.05/2)  &  x <= -qnorm(0.05/2)] <- NA
    return(y)
}

ggplot(data.frame(x = c(-3, 3)), aes(x = x)) +
stat_function(fun = dnorm) +
stat_function(fun = dnorm_limit, geom = "area", fill = "red", alpha = 0.5) +
geom_vline(aes(xintercept = qnorm(0.025)), linetype = "dashed", color = "red") +
annotate("text", x=qnorm(0.025)-0.09, y=0.15, label="2.5% percentile", angle=90) +
geom_vline(aes(xintercept = -qnorm(0.025)), linetype = "dashed", color = "red") +
annotate("text", x=-qnorm(0.025)-0.09, y=0.15, label="97.5% percentile", angle=90) +
geom_vline(aes(xintercept = p_value), linetype = "dashed", color = "orange") +
annotate("text", x=p_value-0.09, y=0.15, label="p-value", angle=90) +
geom_vline(aes(xintercept = z_stat), linetype = "dashed", color = "blue") +
annotate("text", x=z_stat-0.09, y=0.15, label="z-score", angle=90) +
scale_x_continuous(breaks = c(-qnorm(0.025), z_stat, p_value, qnorm(0.025)))

```

### Conclusion:

We know, that if p-value is small enough (less than or equal to the significance level $\alpha$, we reject $H_0$ and do not reject otherwise. The obtained p-value is 0.8546726 and the significance level is 0.05, hence, with 95% of confidence we do not reject $H_0$.

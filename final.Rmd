---
title: "P&S lab4"
authors: Nazar Demchuk, Kozlovskyy Andrea, Maslenchenko Oleksandra
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Required libraries

```{r}
# install.packages("BSDA")
library(BSDA)
library(ggplot2)
```

### Generating data

```{r}
# make this example reproducible
set.seed(0)
n <- 12

# generating data
a <- function(k) {
  res <- (k * log(k * k * n + pi))
  return(res - floor(res))
}

X <- seq(1, 100)
for (idx in 1:100) {
  X[idx] = qnorm(a(idx))
}

Y <- seq(1, 50)
for (idx in 1:50) {
  Y[idx] = qnorm(a(idx + 100))
}

# X
# Y
```

# Problem 1

### Maslenchenko Oleksandra

$$
H_0: \mu_1 = \mu_2 \space vs. \space H_1: \mu_1 \neq \mu_2; \space \sigma_1^2 = \sigma_2^2=1
$$

### Theory:

Since here we test means of two samples, variances are known and both sample sizes are large enough (larger than 30), we can use z-test. Also, since the alternative hypothesis states, that the mean of the first sample is not equal to the mean of the second sample, we will use two-sided z-test. First, let us derive it theoretically:

To estimate $\mu_1-\mu_2$ we can use $\bar{X}-\bar{Y}$ and it would be natural to reject $H_0$ if the obtained value is far from zero.

$$
C_{\alpha} = \brace(x, y): |\bar{X}-\bar{Y}|>c_{\alpha}
$$

According to the Central Limit Theorem, regardless of the distribution of the population, as long as the sample size is large enough (larger than 30), the sampling distribution of the mean will always be normally distributed.

So when we assume that $H_0$ is true, the distribution of $\bar{X} \sim N(\mu_x, \sigma^2/n)$ and $\bar{Y} \sim N(\mu_x, \sigma^2/m)$.

Hence, $\bar{X} - \bar{Y} \sim N(0, \sigma^2/n + \sigma^2/m)$.

$$
Z=Z(X, Y) := \sqrt{\frac{m \cdot n}{m + n}}\frac{\bar{X} - \bar{Y}}{\sigma}
$$

Since Z has standard normal distribution $Z \sim N(0, 1)$, for the test of size $\alpha$ (0.05 in our case):

$$
|z(x, y)| \geq z_{1-\alpha/2}
$$

And the corresponding p-value:

$$
p(x, y) = 2\cdot\Phi(-|z(x,y)|)
$$

### Calculating manually:

```{r}
#calculating z-statistics
z_stat <- sqrt(5000/150)*(mean(X)-mean(Y))
cat("z-score for two-sided z-test ", z_stat)

cat("\n")

#calculating p-value
p_value <- 2*pnorm(-abs(z_stat))
cat("p-value for two-sided z-test ", p_value)
```

### Calculating using built-in function:

```{r}
#usng built-in function to test hypotheses using two-sided z-test
z_test <- z.test(x = X, y = Y, alternative = "two.sided", mu = 0, sigma.x = 1, sigma.y = 1, conf.level = 0.95)
z_test
```

As we can see, the values obtained by calculating manually and using built-in functions match.

### Plot:

Now we can show all the obtained data on the plot: 2.5% and 97.5% percentiles, p-value and z-score. Rejection regions are filled with red color. Since z-score does not belong to them, we do not have to reject $H_0$.

```{r}
dnorm_limit <- function(x) {
    y <- dnorm(x)
    y[x >= qnorm(0.05/2)  &  x <= -qnorm(0.05/2)] <- NA
    return(y)
}

ggplot(data.frame(x = c(-3, 3)), aes(x = x)) +
stat_function(fun = dnorm) +
stat_function(fun = dnorm_limit, geom = "area", fill = "red", alpha = 0.5) +
geom_vline(aes(xintercept = qnorm(0.025)), linetype = "dashed", color = "red") +
annotate("text", x=qnorm(0.025)-0.09, y=0.15, label="2.5% percentile", angle=90) +
geom_vline(aes(xintercept = -qnorm(0.025)), linetype = "dashed", color = "red") +
annotate("text", x=-qnorm(0.025)-0.09, y=0.15, label="97.5% percentile", angle=90) +
geom_vline(aes(xintercept = p_value), linetype = "dashed", color = "orange") +
annotate("text", x=p_value-0.09, y=0.15, label="p-value", angle=90) +
geom_vline(aes(xintercept = z_stat), linetype = "dashed", color = "blue") +
annotate("text", x=z_stat-0.09, y=0.15, label="z-score", angle=90) +
scale_x_continuous(breaks = c(-qnorm(0.025), z_stat, p_value, qnorm(0.025)))

```

### Conclusion:

We know, that if p-value is small enough (less than or equal to the significance level $\alpha$), we reject $H_0$ and do not reject otherwise. The obtained p-value is 0.2450532 and the significance level is 0.05, hence, with 95% of confidence we do not reject $H_0$.

# Problem 2

### Andrea Kozlovskyy

#### To test the equality of variances of two normal populations we use upper-tailed f-test. From task 3.a we can see that these two populations are indeed normal. Our test statistic will be: $$ F (x, y) = S_x^2 / S_y^2$$, where$$ S^2 $$ is a sample variance. From this we can construct our rejection region: $$ C_{\alpha} = \brace F (x, y) >  F (\alpha, n-1, m-1)$$

## Calculating by hand

```{r}
var_x = var(X)
var_y = var(Y)
f_score = max(var_x, var_y) / min(var_x, var_y)
f_score
f_critical <- qf(0.05, 99, 49)
f_critical
```

#### As our data calculated manually is bigger than our critical value, the null hypothesis must be rejected.

```{r}
res.ftest <- var.test(X, Y, alternative = "greater", conf.level = 0.95)
res.ftest
```

### As we can see, the obtained results by calculating manually and using built-in function match.

## Plotting data

```{r}
x_range <- c(0, 100)
ggplot(data.frame(x = c(0, 2.5)), aes(x)) +
  stat_function(fun = df,args = list(df1 = 99, df2 = 49)) +
  geom_vline(aes(xintercept = res.ftest$statistic, linetype = "dashed", color = "blue"))+
  annotate("text", x=res.ftest$statistic-0.09, y=0.15, label="f-score", angle=90)+
  geom_vline(aes(xintercept = f_critical, linetype = "dashed", color = "red"))+
  annotate("text", x=f_critical-0.09, y=0.15, label="f-critical", angle=90)
```

# Problem 3

### Nazar Demchuk

## 3a)

```{r}
mu1 = mean(X)
sigma1 = sd(X)
?seq
x <- seq(from = -4, to = 4, length = 100)
ks.test(X, pnorm, mu1, sigma1)
```

From the output we can see that the test statistic is **0.060557** and the corresponding p-value is **0.8568**. Since the p-value is \>\> .05, we are failed to reject the null hypothesis. We have sufficient evidence to say that the sample data come from a normal distribution.

Comparison of normal cdf and ecdf of our distribution:

```{r}
plot(ecdf(X), col="blue")
dist1 <- pnorm(x, mu1, sigma1)
lines(x, dist1, col = "red", lty = 1, lwd = 2)
```

## 3b)

```{r}
mu2 <- 1
dist2 <- pexp(x, mu2)
ks.test(X, pexp, mu2)
```

Now the test statistic's value is **0.5**, which means that the maximum deviation between two distributions is **0.5** and the p-value is less than **.05**, therefore we reject the null hypothesis and claim that the data we've achieved is not sampled from exponential distribution with $\mu = 1$.

```{r}
plot(ecdf(X), col="blue")
lines(x, dist2, col = "red", lty = 1, lwd = 2)
```

## 3c)

```{r}
ks.test(X, Y)
```

Since p-value is not small enough, we claim null-hypothesis to be true. Thus, X and Y came from the same distribution.

Let's plot them:

```{r}
plot(ecdf(X), col = "red")
lines(ecdf(Y), col = "blue")
```

### Conclusion

This test is useful when we are trying to check whether the sampled data came from some theoretical distribution with known parameters (one-sample test) or check whether two samples came from the same distribution (two-sample test). The test statistic is defined by the greatest deviation of ecdf and cdf in the first case and two ecdf's in the second. The hypotheses testing is performed by initially choosing confidence level $\alpha$ and then by verifying whether test statistic is more than some critical value which depends on $\alpha$.

If it is large enough, we reject null-hypothesis and otherwise we claim that it is true.

So, in this task we've learned how to use one- and two-sample Kolmogoroff-Smirnoff tests in R.
